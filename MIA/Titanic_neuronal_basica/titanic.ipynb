{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 : Titanic\n",
    "\n",
    "La finalidad de la práctica es entrenar una red neuronal para predecir la supervivencia o muerte (0 o 1) de un pasajero del Titanic a partir de otras características, como su edad, sexo, clase...  \n",
    "El objetivo es introducirnos en las redes neuronales y empezar a comprender mejor como funcionan.\n",
    "\n",
    "Eric Salazar Moreira\n",
    "12-03-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones y carga del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Una vista a la estructura general del dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saber el número total de filas y columnas\n",
    "num_filas, num_columnas = df.shape\n",
    "print(\"Número total de filas:\", num_filas)\n",
    "print(\"Número total de columnas:\", num_columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saber el tipo de datos de cada columna\n",
    "tipos_de_datos = df.dtypes\n",
    "print(tipos_de_datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saber si contamos con valores nulos en las columnas\n",
    "valores_nulos = df.isnull().sum()\n",
    "print(valores_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Un resumen estadístico de las variables numéricas\n",
    "summary = df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ver si en las columnas numéricas hay ceros\n",
    "columnas_numericas = df.select_dtypes(include=['int', 'float'])\n",
    "registros_con_0 = (columnas_numericas == 0).sum()\n",
    "print(registros_con_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ver los valores únicos en las columnas categóricas\n",
    "columnas_caracteres = df.select_dtypes(include=['object'])\n",
    "valores_unicos_caracteres = columnas_caracteres.nunique()\n",
    "print(valores_unicos_caracteres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la exploración inicial podemos ver que la distribución de los datos es buena, que con el campo Sex puede hacerse one-hot-encoding y que los registros nulos en el campo Age parecen preocupantes, ya que de primeras parece una variable importante a tener en cuenta para predecir la supervivencia. También hay muchos campos que pueden sobrar, como ticket, cabin, embarked... Puesto que no son relevantes para que una persona sobreviva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de columnas y renombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "df = df.rename(columns={\"Survived\": \"Supervivencia\",\"Pclass\": \"Clase\",\"Sex\": \"Sexo\",\"Age\": \"Edad\",\"SibSp\": \"Hermanos\",\"Parch\": \"Padres_hijos\",\"Fare\": \"Tarifa\", })\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He eliminado las columnas que a mi parecer no afectaban a la supervivencia de los pasajeros y hacían que se tuviese que trabajar con más datos que no ayudaban al futuro modelo. También he renombrado las columnas para tenerlas en español y que me sea más sencillo trabajar con ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de datos\n",
    "Con tal de solo tener datos numéricos y sabiendo que la columna \"Sexo\" es binaria, convertiré los datos de male a 0 y de female a 1 en vez de hacer one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sexo'] = df['Sexo'].replace({'female': 1, 'male': 0})\n",
    "df['Sexo'] = df['Sexo'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputación de datos\n",
    "En la columna \"Edad\" contamos con 177 valores nulos. A continuación voy a ver qué hacer con este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Edad'].mean()\n",
    "correlacion1 = df['Edad'].corr(df['Supervivencia'])\n",
    "print(\"Correlación entre edad y supervivencia:\", correlacion1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_nulos = df.dropna(subset=['Edad'])\n",
    "valores_nulos = df_sin_nulos.isnull().sum()\n",
    "print(valores_nulos)\n",
    "df_sin_nulos['Edad'].mean()\n",
    "num_filas, num_columnas = df_sin_nulos.shape\n",
    "print(\"Número total de filas:\", num_filas)\n",
    "print(\"Número total de columnas:\", num_columnas)\n",
    "correlacion2 = df_sin_nulos['Edad'].corr(df_sin_nulos['Supervivencia'])\n",
    "print(\"Correlación entre edad y supervivencia:\", correlacion2)\n",
    "# Crear el histograma de edades\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df_sin_nulos['Edad'], bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Ajustar etiquetas y título\n",
    "plt.title('Distribución de Edades')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_edad = df['Edad'].mean()\n",
    "df_media = df.copy()\n",
    "df_media['Edad'].fillna(media_edad, inplace=True)\n",
    "valores_nulos = df_media.isnull().sum()\n",
    "print(valores_nulos)\n",
    "num_filas, num_columnas = df_media.shape\n",
    "print(\"Número total de filas:\", num_filas)\n",
    "print(\"Número total de columnas:\", num_columnas)\n",
    "correlacion3 = df_sin_nulos['Edad'].corr(df_sin_nulos['Supervivencia'])\n",
    "print(\"Correlación entre edad y supervivencia:\", correlacion3)\n",
    "\n",
    "# Crear el histograma de edades\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df_media['Edad'], bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Ajustar etiquetas y título\n",
    "plt.title('Distribución de Edades')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediana_edad = df['Edad'].median()\n",
    "df_mediana = df.copy()\n",
    "df_mediana['Edad'].fillna(media_edad, inplace=True)\n",
    "valores_nulos = df_mediana.isnull().sum()\n",
    "print(valores_nulos)\n",
    "num_filas, num_columnas = df_mediana.shape\n",
    "print(\"Número total de filas:\", num_filas)\n",
    "print(\"Número total de columnas:\", num_columnas)\n",
    "correlacion3 = df_sin_nulos['Edad'].corr(df_sin_nulos['Supervivencia'])\n",
    "print(\"Correlación entre edad y supervivencia:\", correlacion3)\n",
    "\n",
    "# Crear el histograma de edades\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(df_mediana['Edad'], bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Ajustar etiquetas y título\n",
    "plt.title('Distribución de Edades')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándome en las gráficas y viendo como se distribuyen las edades al imputarlas tanto con media como con mediana, he decidido que lo más correcto es eliminar los registros sin edad del dataframe, esto se debe a que imputando con media o mediana se pierde mucho la distribución normal de las edades reales y se crea un pico demasiado denso, los registros sin edad tampoco comportan una parte muy importante del dataframe y borrarlos no afecta al nivel de correlación, como se puede comprobar. Si hubiesen datos a partir de los cuales poder predecir la edad, sería una buena práctica hacer una imputacion calculada, pero en este caso no es posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sin_nulos.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['int', 'float'])\n",
    "plt.figure(figsize=(10, 5))\n",
    "corr = df_numeric.corr()\n",
    "sns.heatmap(corr, cmap=\"BrBG\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay una relación muy amplia entre la supervivencia de los pasajeros y sus características, lo más destacable es que el sexo sí que afecta a la supervivencia de los pasajeros, igual que la tarifa que pagaron por el viaje, el resto de campos no afectan a la supervivencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)\n",
    "# Dividir los datos en características (X) y la variable objetivo (y)\n",
    "X = df.drop('Supervivencia', axis=1)  # características\n",
    "y = df['Supervivencia']  # variable objetivo\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba (70% entreno, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He dividido los datos en X e Y y en conjuntos para entrenamiento y prueba, un 70% para entreno y un 30% para testing. Donde: \n",
    "1. X_train: características de entrenamiento\n",
    "2. X_test: características de prueba\n",
    "3.  y_train: etiquetas de entrenamiento\n",
    "4. y_test: etiquetas de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir la primera capa oculta\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "# Añadir la capa de salida\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He creado el modelo con los requisitos definidos en la práctica, activación relu, salida sigmoid puesto que es un resultado binario y optimizador adam. Solo una capa oculta puesto que añadiendo más de una bajaba el rendimiento, ya que eran excesivas para los pocos datos con los que la red está tratando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo y visualización de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "# Obtener la historia de entrenamiento\n",
    "history = model.fit(X_train, y_train, epochs=4, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Obtener la pérdida y la precisión durante el entrenamiento\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plotear la pérdida\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotear la precisión\n",
    "plt.plot(epochs, train_accuracy, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Pérdida en el conjunto de prueba:\", loss)\n",
    "print(\"Precisión en el conjunto de prueba:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo los plots y los resultados del modelo, puedo llegar a varias conclusiones:\n",
    "\n",
    "1. **Rendimiento general**: El modelo muestra una precisión del 76.74% en el conjunto de prueba, lo que indica una capacidad razonable para capturar patrones en los datos.\n",
    "\n",
    "2. **Estabilidad durante el entrenamiento**: A lo largo de las cuatro épocas, tanto la pérdida como la precisión en el conjunto de validación muestran una tendencia estable, sugiriendo que el modelo no está sobreajustando o subajustando en exceso.\n",
    "\n",
    "3. **Posible sobreajuste**: Aunque la brecha entre la precisión en el conjunto de entrenamiento y el conjunto de validación sugiere cierto sobreajuste, este efecto parece ser moderado y manejable.\n",
    "\n",
    "4. **Ajuste adicional**: Dado que la precisión en el conjunto de validación no ha alcanzado un pico y la pérdida no ha convergido completamente, podría ser beneficioso explorar un entrenamiento adicional para mejorar aún más el rendimiento.\n",
    "\n",
    "En resumen, el modelo funciona bien y cumple con su cometido, pero existe margen para modificar parámetros y mejorar su rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
